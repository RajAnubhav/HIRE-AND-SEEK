{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  job_comp = pd.read_sql(\"SELECT * FROM job \",my_conn)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:38: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  profile = pd.read_sql(\"SELECT * FROM stud_profile \",my_conn)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comp['tags']=comp['tags'].apply(lambda x:\" \".join(x))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:224: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comp['tags'] = comp['tags'].apply(lambda x:x.lower())\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job.dropna(inplace = True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:306: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['place'] = c_C()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['database_worked_with'] = c_DW()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:339: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['language_worked_with'] = c_LWW()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['collab_tools'] = c_NCTWW()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['opsys'] = c_OS()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:361: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['plateform_worked_with'] = c_PlatformWorkedWith()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:368: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['degree'] = c_UndergradMajor()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['place'] = job['place'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['database_worked_with'] = job['database_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:389: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['language_worked_with'] = job['language_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:390: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['collab_tools'] = job['collab_tools'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['plateform_worked_with'] = job['plateform_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['degree'] = job['degree'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job['tags'] =job['place'] + job[\"database_worked_with\"] + job['language_worked_with'] + job['collab_tools'] + job['opsys'] + job['plateform_worked_with'] + job['degree']\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:429: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job_seekr['tags']=job_seekr['tags'].apply(lambda x:\" \".join(x))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14384\\3830287288.py:435: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job_seekr['tags'] = job_seekr['tags'].apply(lambda x:x.lower())\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 466\u001b[0m\n\u001b[0;32m    460\u001b[0m vector2\u001b[39m.\u001b[39mshape\n\u001b[0;32m    463\u001b[0m \u001b[39m# In[160]:\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m cv\u001b[39m.\u001b[39;49mget_feature_names()\n\u001b[0;32m    469\u001b[0m \u001b[39m# In[161]:\u001b[39;00m\n\u001b[0;32m    472\u001b[0m vector1 \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mfit_transform(job_seekr[\u001b[39m'\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[103]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "# In[104]:\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "my_conn = mysql.connector.connect(\n",
    "      host=\"localhost\",\n",
    "      user=\"root\",\n",
    "      passwd=\"\",\n",
    "      database=\"jobship\"\n",
    "    )\n",
    "####### end of connection ####\n",
    "job_comp = pd.read_sql(\"SELECT * FROM job \",my_conn)\n",
    "job_comp.head(50)\n",
    "\n",
    "\n",
    "# In[105]:\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "my_conn = mysql.connector.connect(\n",
    "      host=\"localhost\",\n",
    "      user=\"root\",\n",
    "      passwd=\"\",\n",
    "      database=\"jobship\"\n",
    "    )\n",
    "####### end of connection ####\n",
    "profile = pd.read_sql(\"SELECT * FROM stud_profile \",my_conn)\n",
    "profile.head(50)\n",
    "\n",
    "\n",
    "# In[106]:\n",
    "\n",
    "\n",
    "cmp = job_comp\n",
    "job = profile\n",
    "\n",
    "\n",
    "# In[107]:\n",
    "\n",
    "\n",
    "job.head(100)\n",
    "\n",
    "\n",
    "# In[108]:\n",
    "\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[109]:\n",
    "\n",
    "\n",
    "cmp = cmp.loc[:,['job_id','domain', 'company','jobtitle','skills','joblocation_address']]\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "cmp.isnull().sum()\n",
    "\n",
    "\n",
    "# In[111]:\n",
    "\n",
    "\n",
    "cmp.dropna(inplace = True)\n",
    "j = len(cmp.shape)\n",
    "\n",
    "\n",
    "# In[112]:\n",
    "\n",
    "\n",
    "cmp.duplicated().sum()\n",
    "\n",
    "\n",
    "# In[113]:\n",
    "\n",
    "\n",
    "cmp.shape\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "\n",
    "def convert_skills():\n",
    "    data = []\n",
    "    for i in range(len(cmp)):\n",
    "        data.append(cmp.iloc[i].skills.split(\",\"))\n",
    "    return data\n",
    "    \n",
    "\n",
    "\n",
    "# In[115]:\n",
    "\n",
    "\n",
    "data = convert_skills()\n",
    "cmp['skills'] = data\n",
    "cmp['skills'].head()\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "\n",
    "def convert_jobtitle():\n",
    "    data2 = []\n",
    "    for i in range(len(cmp)):\n",
    "        data2.append(cmp.iloc[i].jobtitle.split(\",\"))\n",
    "    return data2\n",
    "\n",
    "cmp['jobtitle'] = convert_jobtitle()\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[118]:\n",
    "\n",
    "\n",
    "#def convert_Company():\n",
    "  #  data3 = []\n",
    "   # for i in range(len(cmp)):\n",
    "    #    data3.append(cmp.iloc[i].company.split(\",\"))\n",
    "    #return data3\n",
    "#data3 = convert_Company()\n",
    "#cmp['company'] = data3\n",
    "\n",
    "def convert_joblocation_address():\n",
    "    data4 = []\n",
    "    for i in range(len(cmp)):\n",
    "        data4.append(cmp.iloc[i].joblocation_address.split(\" \"))\n",
    "    return data4\n",
    "data4 = convert_joblocation_address()\n",
    "cmp['joblocation_address'] = data4\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "#cmp['jobdescription']=cmp['jobdescription'].apply(lambda x:x.split())\n",
    "\n",
    "\n",
    "# In[120]:\n",
    "\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[121]:\n",
    "\n",
    "\n",
    "cmp['jobtitle'] = cmp['jobtitle'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "\n",
    "#cmp['jobdescription']=cmp['jobdescription'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "cmp['skills']=cmp['skills'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "cmp['joblocation_address']=cmp['joblocation_address'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "\n",
    "\n",
    "# In[123]:\n",
    "\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[124]:\n",
    "\n",
    "\n",
    "cmp['tags'] = cmp['jobtitle'] + cmp['skills'] + cmp['joblocation_address']\n",
    "\n",
    "\n",
    "# In[125]:\n",
    "\n",
    "\n",
    "cmp.head()\n",
    "\n",
    "\n",
    "# In[126]:\n",
    "\n",
    "\n",
    "comp =  cmp[['job_id','domain','company','tags']]\n",
    "\n",
    "\n",
    "# In[127]:\n",
    "\n",
    "\n",
    "comp.head()\n",
    "\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "comp['tags']=comp['tags'].apply(lambda x:\" \".join(x))\n",
    "\n",
    "\n",
    "# In[129]:\n",
    "\n",
    "\n",
    "comp.head()\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "\n",
    "comp['tags'] = comp['tags'].apply(lambda x:x.lower())\n",
    "\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "\n",
    "comp.head()\n",
    "\n",
    "\n",
    "# In[132]:\n",
    "\n",
    "\n",
    "comp.shape\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "\n",
    "comp.head()\n",
    "\n",
    "\n",
    "# In[134]:\n",
    "\n",
    "\n",
    "comp['tags'][0]\n",
    "\n",
    "\n",
    "# In[135]:\n",
    "\n",
    "\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[136]:\n",
    "\n",
    "\n",
    "job = job[['id','name','place','database_worked_with','language_worked_with','collab_tools','opsys','plateform_worked_with','degree',]]\n",
    "\n",
    "\n",
    "# In[137]:\n",
    "\n",
    "\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[138]:\n",
    "\n",
    "\n",
    "job.isnull().sum()\n",
    "\n",
    "\n",
    "# In[139]:\n",
    "\n",
    "\n",
    "job.shape\n",
    "\n",
    "\n",
    "# In[140]:\n",
    "\n",
    "\n",
    "job.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# In[141]:\n",
    "\n",
    "\n",
    "#def c_MB():\n",
    " #   data5 = []\n",
    "  #  for i in range(len(job)):\n",
    "   #     data5.append(job.iloc[i].summary.split(\",\"))\n",
    "    #return data5\n",
    "#job['summary'] = c_MB()\n",
    "\n",
    "\n",
    "# In[142]:\n",
    "\n",
    "\n",
    "def c_C():\n",
    "    data6 = []\n",
    "    for i in range(len(job)):\n",
    "        data6.append(job.iloc[i].place.split(\",\"))\n",
    "    return data6\n",
    "job['place'] = c_C()\n",
    "\n",
    "\n",
    "# In[143]:\n",
    "\n",
    "\n",
    "def c_DW():\n",
    "    data7 = []\n",
    "    for i in range(len(job)):\n",
    "        data7.append(job.iloc[i].database_worked_with.split(\",\"))\n",
    "    return data7\n",
    "job['database_worked_with'] = c_DW()\n",
    "\n",
    "\n",
    "# In[144]:\n",
    "\n",
    "\n",
    "#def c_DT():\n",
    "#    data8 = []\n",
    "#    for i in range(len(job)):\n",
    "#        data8.append(job.iloc[i].DevType.split(\",\"))\n",
    "#    return data8\n",
    "#job['DevType'] = c_DT()\n",
    "\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "\n",
    "def c_LWW():\n",
    "    data9 = []\n",
    "    for i in range(len(job)):\n",
    "        data9.append(job.iloc[i].language_worked_with.split(\",\"))\n",
    "    return data9\n",
    "job['language_worked_with'] = c_LWW()\n",
    "\n",
    "def c_NCTWW():\n",
    "    data10 = []\n",
    "    for i in range(len(job)):\n",
    "        data10.append(job.iloc[i].collab_tools.split(\",\"))\n",
    "    return data10\n",
    "job['collab_tools'] = c_NCTWW()\n",
    "\n",
    "def c_OS():\n",
    "    data11 = []\n",
    "    for i in range(len(job)):\n",
    "        data11.append(job.iloc[i].opsys.split(\",\"))\n",
    "    return data11\n",
    "job['opsys'] = c_OS()\n",
    "\n",
    "\n",
    "def c_PlatformWorkedWith():\n",
    "    data12 = []\n",
    "    for i in range(len(job)):\n",
    "        data12.append(job.iloc[i].plateform_worked_with.split(\",\"))\n",
    "    return data12\n",
    "job['plateform_worked_with'] = c_PlatformWorkedWith()\n",
    "\n",
    "def c_UndergradMajor():\n",
    "    data13 = []\n",
    "    for i in range(len(job)):\n",
    "        data13.append(job.iloc[i].degree.split(\",\"))\n",
    "    return data13\n",
    "job['degree'] = c_UndergradMajor()\n",
    "    \n",
    "\n",
    "\n",
    "# In[146]:\n",
    "\n",
    "\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "\n",
    "job['place'] = job['place'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[148]:\n",
    "\n",
    "\n",
    "job['database_worked_with'] = job['database_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "job['language_worked_with'] = job['language_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "job['collab_tools'] = job['collab_tools'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "job['plateform_worked_with'] = job['plateform_worked_with'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "job['degree'] = job['degree'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "#job['MainBranch'] = job['MainBranch'].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "\n",
    "\n",
    "# In[149]:\n",
    "\n",
    "\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[150]:\n",
    "\n",
    "\n",
    "job['tags'] =job['place'] + job[\"database_worked_with\"] + job['language_worked_with'] + job['collab_tools'] + job['opsys'] + job['plateform_worked_with'] + job['degree']  \n",
    "\n",
    "\n",
    "# In[151]:\n",
    "\n",
    "\n",
    "job.head()\n",
    "\n",
    "\n",
    "# In[152]:\n",
    "\n",
    "\n",
    "job_seekr = job[['id','name', 'tags']]\n",
    "\n",
    "\n",
    "# In[153]:\n",
    "\n",
    "\n",
    "job_seekr.head()\n",
    "\n",
    "\n",
    "# In[154]:\n",
    "\n",
    "\n",
    "job_seekr['tags']=job_seekr['tags'].apply(lambda x:\" \".join(x))\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "job_seekr['tags'] = job_seekr['tags'].apply(lambda x:x.lower())\n",
    "\n",
    "\n",
    "# In[156]:\n",
    "\n",
    "\n",
    "job_seekr['tags'][7]\n",
    "\n",
    "\n",
    "# In[157]:\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "model = CountVectorizer()\n",
    "model.fit(job_seekr['tags'])\n",
    "cv = CountVectorizer(max_features=117,stop_words='english')\n",
    "\n",
    "\n",
    "# In[158]:\n",
    "\n",
    "\n",
    "vector2 = cv.fit_transform(comp['tags']).toarray()\n",
    "\n",
    "\n",
    "# In[159]:\n",
    "\n",
    "\n",
    "vector2.shape\n",
    "\n",
    "\n",
    "# In[160]:\n",
    "\n",
    "\n",
    "cv.get_feature_names()\n",
    "\n",
    "\n",
    "# In[161]:\n",
    "\n",
    "\n",
    "vector1 = cv.fit_transform(job_seekr['tags']).toarray()\n",
    "vector1.shape\n",
    "\n",
    "\n",
    "# In[162]:\n",
    "\n",
    "\n",
    "cv.get_feature_names()\n",
    "\n",
    "\n",
    "# In[163]:\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "# In[164]:\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "# In[165]:\n",
    "\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    \n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "\n",
    "# In[166]:\n",
    "\n",
    "\n",
    "job_seekr['tags'] = job_seekr['tags'].apply(stem)\n",
    "\n",
    "\n",
    "# In[167]:\n",
    "\n",
    "\n",
    "comp['tags'] = comp['tags'].apply(stem)\n",
    "\n",
    "\n",
    "# In[168]:\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# In[169]:\n",
    "\n",
    "\n",
    "simalarity = cosine_similarity(vector1, vector2)\n",
    "\n",
    "\n",
    "# In[170]:\n",
    "\n",
    "\n",
    "simalarity[0]\n",
    "\n",
    "\n",
    "# In[171]:\n",
    "\n",
    "\n",
    "sorted(list(enumerate(simalarity[0])), reverse = False,key = lambda x:x[1])[0:5]\n",
    "\n",
    "\n",
    "# In[172]:\n",
    "\n",
    "\n",
    "def recommend(int):\n",
    "    job_index=job_seekr[job_seekr['id'] == int].index[0]\n",
    "    distances = simalarity[job_index]\n",
    "    company_list = sorted(list(enumerate(distances)), reverse = True,key = lambda x:x[1])[0:5]\n",
    "    id = []\n",
    "    \n",
    "    for i in company_list:\n",
    "        id.append(comp.iloc[i[0]].job_id)\n",
    "    print(id)\n",
    "        \n",
    "    return id\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[173]:\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[174]:\n",
    "\n",
    "\n",
    "comp.head(12)\n",
    "\n",
    "\n",
    "# In[175]:\n",
    "\n",
    "\n",
    "job_seekr.head()\n",
    "\n",
    "\n",
    "# In[176]:\n",
    "\n",
    "\n",
    "job_seekr['id'].values\n",
    "\n",
    "\n",
    "# In[177]:\n",
    "\n",
    "\n",
    "job_seekr.to_dict()\n",
    "\n",
    "\n",
    "# In[178]:\n",
    "\n",
    "\n",
    "comp.to_dict()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a694dde74ded22b8cb10b6383ba489cb4edbda2213ae49c3ec1cf8d6d50434dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
